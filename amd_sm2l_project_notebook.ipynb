{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "amd-sm2l-project-notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidegavio/amd-sm2l-project/blob/main/amd_sm2l_project_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoYTal8F893L"
      },
      "source": [
        "# Joint project AMD - SM2L\n",
        "Davide Gavio - 930569\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDhDflF2Z4RG"
      },
      "source": [
        "# Important disclaimer\n",
        "When an operation modifies datasets, there are some lines of codes that show to the user some information about the resulting dataset. This could lead to some slowdown in the code execution. For a faster execution it's necessary to uncomment all those informative lines of code (count(), show(), ecc. calls)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KprEsQWz7NTh"
      },
      "source": [
        "# Google Colab settings\n",
        "Those actions need to be done in order to have the notebook working on Google Colab. \n",
        "If the notebook is executed elsewhere skip to the next cell.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mk1cDVP62_Rf"
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://downloads.apache.org/spark/spark-3.0.1/spark-3.0.1-bin-hadoop2.7.tgz   \n",
        "!tar xf spark-3.0.1-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark pyspark seaborn kaggle scikit-learn matplotlib pandas progressbar2\n",
        "!rm spark-3.0.1-bin-hadoop2.7.tgz\n",
        "with open('/content/spark-3.0.1-bin-hadoop2.7/conf/spark-defaults.conf', 'w') as file_object:\n",
        "  file_object.write('spark.driver.memory              15g')\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.1-bin-hadoop2.7\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHnXTcoq7J5i"
      },
      "source": [
        "# PySpark settings\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUn7Dsf99bRS"
      },
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('amd-sm2l-project').master(\"local[*]\").getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8inu3DYIcba"
      },
      "source": [
        "# Imports and settings\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8ApGnI3If3d"
      },
      "source": [
        "!mkdir ~/.kaggle\n",
        "!echo '{\"username\":\"davidegavio\",\"key\":\"f4540434f20370f2bf34e2f9010b647e\"}' > ~/.kaggle/kaggle.json\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzUMYDbp2nx_"
      },
      "source": [
        "from matplotlib.pyplot import xlabel, ylabel\n",
        "import pandas as pd\n",
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.conf import SparkConf\n",
        "import pyspark.sql.functions as f\n",
        "from pyspark.sql.types import DoubleType, Row\n",
        "from pyspark.context import SparkContext\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import Imputer, MinMaxScaler, OneHotEncoder, VectorAssembler, StringIndexer, StandardScaler\n",
        "from pyspark.mllib.linalg import DenseVector\n",
        "from pyspark.mllib.regression import LabeledPoint, RidgeRegressionWithSGD\n",
        "from pyspark.mllib.evaluation import RegressionMetrics\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml.feature import ChiSqSelector, VectorIndexer\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "from zipfile import ZipFile\n",
        "import os\n",
        "from datetime import datetime\n",
        "from pyspark.sql.types import *\n",
        "import math\n",
        "import kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vNXHUuZ83BU"
      },
      "source": [
        "'''\n",
        "  learning_rate: gradient descent update step\n",
        "  n_iterations: iterations of the gradient descent\n",
        "  alphas: regularization factors tested with grid search\n",
        "  alpha: default alpha if grid search is not applied\n",
        "  num_partitions: number of partitions of df data structures\n",
        "'''\n",
        "learning_rate = 0.00001\n",
        "n_iterations = 150\n",
        "lowest_error = float('inf')\n",
        "alphas = [1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1, 10, 100, 1000]\n",
        "alpha = 0.01\n",
        "num_partitions = spark.sparkContext.defaultParallelism * 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oo2O7olfI3zd"
      },
      "source": [
        "print('Parallelism info')\n",
        "print(\"Default parallelism: {}\".format(spark.sparkContext.defaultParallelism))\n",
        "print(\"Custom parallelism: {}\\n\".format(num_partitions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCoQaLls9pbz"
      },
      "source": [
        "# Ridge Regression\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7K7Hh3i2nyT"
      },
      "source": [
        "import numpy as np \n",
        "import math\n",
        "from datetime import datetime\n",
        "from pyspark.sql import SparkSession\n",
        "from progressbar import ProgressBar\n",
        " \n",
        " \n",
        " \n",
        "class SparkRidgeRegression(object):\n",
        "    \"\"\" \n",
        "        Parameters:\n",
        "        -----------\n",
        "        n_iterations: float\n",
        "            The number of training iterations the algorithm will tune the weights for.\n",
        "        learning_rate: float\n",
        "            The step length that will be used when updating the weights.\"\"\"\n",
        "    def __init__(self, n_iterations, learning_rate, reg_factor):\n",
        "        self.n_iterations = n_iterations\n",
        "        self.learning_rate = learning_rate\n",
        "        self.reg_factor = reg_factor\n",
        "    \n",
        "    def get_training_errors(self):\n",
        "        return self.training_errors\n",
        "    \n",
        "    def set_training_errors(self, error):\n",
        "        self.training_errors = error\n",
        " \n",
        "    def squared_error(self, target, prediction):\n",
        "        return (target - prediction) ** 2\n",
        " \n",
        "    def root_mean_squared_error(self, predictions):\n",
        "        return np.sqrt(predictions.map(lambda p: self.squared_error(*p)).mean())\n",
        " \n",
        "    def mean_squared_error(self, predictions):\n",
        "        return predictions.map(lambda p: self.squared_error(p[0], p[1])).mean()\n",
        " \n",
        "    def mean_absolute_error(self, predictions):\n",
        "        return np.abs(predictions.map(lambda prediction: prediction[1] - prediction[0]).reduce(lambda a, b: a + b))/predictions.count()\n",
        "    \n",
        "    def r2(self, predictions):\n",
        "        mean_ = predictions.rdd.map(lambda t: t[0]).mean()\n",
        "        sum_squares = predictions.rdd.map(lambda t: (t[0] - mean_)**2).sum()\n",
        "        residual_sum_squares = predictions.rdd.map(lambda t: self.squared_error(*t)).sum()\n",
        "        return 1 - (residual_sum_squares / sum_squares)\n",
        " \n",
        " \n",
        "    def summand_func(self, example):\n",
        "        return (self.weights.dot(DenseVector(example.features)) - example.label) * example.features\n",
        " \n",
        "    \n",
        "    def fit(self, observations):\n",
        "        progressbar = ProgressBar()\n",
        "        features_number = len(observations.take(1)[0].features)\n",
        "        self.training_errors = []\n",
        "        self.weights = np.zeros(features_number)        \n",
        "        start = datetime.now()\n",
        "        # Perform gradient descent for n_iterations\n",
        "        for i in progressbar(range(self.n_iterations)):\n",
        "          # Get the prediction given an example and the current weights\n",
        "          predictions = observations.map(lambda example: self.predict(example)) # Result [label, prediction]\n",
        "          # Calculate l2 loss\n",
        "          regularization = self.reg_factor * self.weights\n",
        "          self.training_errors.append(self.root_mean_squared_error(predictions))\n",
        "          # Gradient of l2 loss w.r.t w\n",
        "          grad_w = observations.map(lambda example: DenseVector(self.summand_func(example))).reduce(lambda x, y: x + y) + regularization\n",
        "          # Update the weights\n",
        "          self.weights -= self.learning_rate * grad_w\n",
        "          if i == self.n_iterations-1:\n",
        "            float_predictions = predictions.map(lambda xs: [float(x) for x in xs])\n",
        "            predictions_df = float_predictions.toDF(['label', 'predictions'])\n",
        "            print('From scratch training MSE: {}'.format(self.mean_squared_error(predictions=predictions)))\n",
        "            print('From scratch training RMSE: {}'.format(self.root_mean_squared_error(predictions=predictions)))\n",
        "            print('From scratch training MAE: {}'.format(self.mean_absolute_error(predictions=predictions)))\n",
        "            print('From scratch training R2: {}'.format(self.r2(predictions_df)))\n",
        " \n",
        "    def predict(self, example):\n",
        "        return (example.label, self.weights.dot(DenseVector(example.features)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHV_XrIA9xcy"
      },
      "source": [
        "# Utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8LrT0C62nyg"
      },
      "source": [
        "def to_labeledpoint(row):\n",
        "  row_dict = row.asDict()\n",
        "  target = np.array(row_dict['scaled_target'][0])\n",
        "  features = np.array(row_dict['scaled_features']).tolist()\n",
        "  features.insert(0, 1.0)\n",
        "  return LabeledPoint(target, features)\n",
        " \n",
        "def remove_outliers(df):\n",
        "  quantiles = df.approxQuantile(label_to_predict, [0.25, 0.75], 0.1)\n",
        "  iqr = quantiles[1] - quantiles[0]\n",
        "  if iqr != 0:\n",
        "    df = df.filter(f.col(label_to_predict).between(quantiles[0] - (1.5 * iqr), quantiles[1] + (1.5 * iqr)))\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ewvj9CPvCbEQ"
      },
      "source": [
        "# Dataset download"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcFw1LhWCj0n"
      },
      "source": [
        "print('Downloading necessary files from Kaggle')\n",
        "startTime = datetime.now()\n",
        "kaggle.api.authenticate()\n",
        "!mkdir ~/.kaggle\n",
        "!echo '{\"username\":\"davidegavio\",\"key\":\"f4540434f20370f2bf34e2f9010b647e\"}' > ~/.kaggle/kaggle.json\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!mkdir ./datasets\n",
        "!kaggle datasets download census/2013-american-community-survey -p ./datasets\n",
        "with ZipFile('./datasets/2013-american-community-survey.zip', 'r') as zipObj:\n",
        "   zipObj.extractall('./datasets/2013-american-community-survey')\n",
        "os.remove('./datasets/2013-american-community-survey.zip')\n",
        "print('Your download has been completed in: {}'.format(datetime.now() - startTime))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tj4yxo3290hH"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "By7ssonw2nys"
      },
      "source": [
        "%%time\n",
        "print('Reading from csv')\n",
        "df_a = spark.read.csv('/content/datasets/2013-american-community-survey/ss13pusa.csv', inferSchema=True, header=True).limit(35000)\n",
        "df_b = spark.read.csv('/content/datasets/2013-american-community-survey/ss13pusb.csv', inferSchema=True, header=True).limit(35000)\n",
        "df = df_a.union(df_b)\n",
        "df = df.repartition(numPartitions=num_partitions)\n",
        "label_to_predict = 'WAGP'\n",
        "drop_thresh = .66\n",
        "print(f\"The shape is {df.count():d} rows by {len(df.columns):d} columns.\")\n",
        "print('The dataframe is divided in {} partitions'.format(df.rdd.getNumPartitions()))\n",
        "print('==> Done\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0RBJ-wFv5sJ"
      },
      "source": [
        "df.describe().show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlFlUp4vtBlb"
      },
      "source": [
        "df.select(label_to_predict).describe().show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XwZz1ei2ny4"
      },
      "source": [
        "%%time\n",
        "print('Dropping useless columns, columns and rows with more than {}% of null values'.format(drop_thresh*100))\n",
        "df = df.select(*(f.col(c).cast(\"float\").alias(c) for c in df.columns)) # Casting the dataframe to float\n",
        "df = df.drop('RT', 'PINCP ', 'PERNP' ) # Removing unnecessary columns\n",
        "count_before = df.count()\n",
        "thresh = int(len(df.columns)*drop_thresh)\n",
        "df = df.dropna(thresh=thresh) # Dropping rows with more than 66% of null values\n",
        "print('Dropped {} rows with less than {}% of non-null values'.format(count_before-df.count(), drop_thresh*100))\n",
        "print('Keeping only rows with non-null value in target position')\n",
        "count_before = df.count()\n",
        "df = df.filter(df[label_to_predict].isNotNull()) # Keeping only the rows with not-null values in the corresponding label\n",
        "data_agg = df.agg(*[f.count(f.when(f.isnull(c), c)).alias(c) for c in df.columns])\n",
        "print('Dropped {} rows with with null in {} column'.format(count_before-df.count(), label_to_predict))\n",
        "count_before = df.count()\n",
        "col_before = len(df.columns)\n",
        "over_thresh_col = df.select([(f.count(f.when(f.col(c).isNull(), c))/count_before).alias(c) for c in df.columns])\n",
        "scheme = df.columns\n",
        "null_distr = over_thresh_col.collect()[0].asDict().values()\n",
        "for i in np.where(np.array(list(null_distr)) > ((1 - drop_thresh)))[0]:\n",
        "  df = df.drop(scheme[i])\n",
        "print('Dropped {} columns with less than {}% of non-null values'.format(col_before-len(df.columns), drop_thresh*100))\n",
        "print(f\"The shape is {df.count():d} rows by {len(df.columns):d} columns.\")\n",
        "print('==> Done\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnqUpncPSWFq"
      },
      "source": [
        "df.select(label_to_predict).describe().show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fREFKGcDI-vo"
      },
      "source": [
        "%%time\n",
        "print('Removing outliers')\n",
        "df = remove_outliers(df)\n",
        "print(f\"The shape is {df.count():d} rows by {len(df.columns):d} columns.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSAFdAyu2nzE"
      },
      "source": [
        "%%time\n",
        "imput_strategy = 'mean'\n",
        "print('Filling remaining null values with {} of each column'.format(imput_strategy))\n",
        "imputer = Imputer() # Filling missing values with mean of the column\n",
        "imputer.setInputCols(df.columns)\n",
        "imputer.setOutputCols(df.columns)\n",
        "imputer.setStrategy(imput_strategy)\n",
        "df = imputer.fit(df).transform(df)\n",
        "print('==> Done\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5Q3lUZDTR7Z"
      },
      "source": [
        "df.select(label_to_predict).describe().show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WX-LX2Cy2nzO"
      },
      "source": [
        "%%time\n",
        "print('Choosing top features and assembling vectors')\n",
        "feature_columns = df.columns\n",
        "feature_columns.remove(label_to_predict)\n",
        "features_assembler = VectorAssembler(inputCols=feature_columns, outputCol='features')\n",
        "feature_selector = ChiSqSelector(numTopFeatures=50, featuresCol=\"features\", outputCol=\"selected_features\", labelCol=label_to_predict)\n",
        "target_assembler = VectorAssembler(inputCols=[label_to_predict], outputCol='target')\n",
        "df = Pipeline(stages=[features_assembler, target_assembler, feature_selector]).fit(df).transform(df)\n",
        "print(f\"The shape is {df.count():d} rows by {feature_selector.getNumTopFeatures():d} columns.\")\n",
        "print('==> Done\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uk2w2MpOUnK_"
      },
      "source": [
        "df.select('selected_features', 'target').show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIuiUbSK5KCh"
      },
      "source": [
        "%%time\n",
        "print('Standardizing and splitting the dataset')\n",
        "to_split_df = df.select('target', 'selected_features')\n",
        "to_label_train_set, to_label_validation_set, to_label_test_set = to_split_df.randomSplit(weights=[.6, .2, .2], seed=6)\n",
        "features_standardscaler = StandardScaler(inputCol='selected_features', outputCol='scaled_features', withStd=True, withMean=True)\n",
        "target_standardscaler = StandardScaler(inputCol='target', outputCol='scaled_target', withStd=True, withMean=True)\n",
        "model = Pipeline(stages=[features_standardscaler, target_standardscaler]).fit(to_label_train_set)\n",
        "scaled_training_set = model.transform(to_label_train_set)\n",
        "scaled_validation_set = model.transform(to_label_validation_set)\n",
        "scaled_test_set = model.transform(to_label_test_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UR_gl15NWCzu"
      },
      "source": [
        "scaled_training_set.select('scaled_features', 'scaled_target').show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zsADoPQ2nzZ"
      },
      "source": [
        "%%time\n",
        "print('Creating labeled points')\n",
        "to_label_train = scaled_training_set.select('scaled_target', 'scaled_features')\n",
        "to_label_validation = scaled_validation_set.select('scaled_target', 'scaled_features')\n",
        "to_label_test = scaled_test_set.select('scaled_target', 'scaled_features')\n",
        "labeled_train_df = to_label_train.rdd.map(lambda row: to_labeledpoint(row))\n",
        "labeled_validation_df = to_label_validation.rdd.map(lambda row: to_labeledpoint(row))\n",
        "labeled_test_df = to_label_test.rdd.map(lambda row: to_labeledpoint(row))\n",
        "labeled_train_df = labeled_train_df.repartition(num_partitions)\n",
        "labeled_validation_df = labeled_validation_df.repartition(num_partitions)\n",
        "labeled_test_df = labeled_test_df.repartition(num_partitions)\n",
        "labeled_train_df.cache()\n",
        "labeled_validation_df.cache()\n",
        "labeled_test_df.cache()\n",
        "print('Training set count: {} divided in {} partitions'.format(labeled_train_df.count(), labeled_train_df.getNumPartitions()))\n",
        "print('Validation set count: {} divided in {} partitions'.format(labeled_validation_df.count(), labeled_validation_df.getNumPartitions()))\n",
        "print('Test set count: {} divided in {} partitions'.format(labeled_test_df.count(), labeled_test_df.getNumPartitions()))\n",
        "print('==> Done\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWo58RTF6YpR"
      },
      "source": [
        "print('Training and predictions will work on ')\n",
        "labeled_train_df.take(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JnyRXvNB8ID"
      },
      "source": [
        "# Best model individuation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZQN11Tb2-xp"
      },
      "source": [
        "%%time\n",
        "from progressbar import ProgressBar\n",
        "progressbar = ProgressBar()\n",
        "print('Finding regularization factor using grid search')\n",
        "best_reg_factor = 0\n",
        "mean_squared_errors = []\n",
        "for candidate_reg_factor in progressbar(alphas):\n",
        "  print('Trying using {} as regularization factor'.format(candidate_reg_factor))\n",
        "  mean_squared_error = 0\n",
        "  candidate_rr = SparkRidgeRegression(n_iterations=n_iterations, learning_rate=0.00001, reg_factor=candidate_reg_factor)\n",
        "  candidate_rr.fit(labeled_train_df)\n",
        "  print('Validating')\n",
        "  candidate_pred = labeled_validation_df.map(lambda prediction: candidate_rr.predict(prediction))\n",
        "  mean_squared_error = candidate_rr.mean_squared_error(predictions=candidate_pred)\n",
        "  mean_squared_errors.append(mean_squared_error)\n",
        "  if mean_squared_error < lowest_error:\n",
        "    print('Currently best regularization factor: {}'.format(candidate_reg_factor))\n",
        "    best_reg_factor = candidate_reg_factor\n",
        "    lowest_error = mean_squared_error\n",
        "alpha = best_reg_factor\n",
        "print('Grid search terminated, chosen regularization factor: {}'.format(best_reg_factor))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iz1adksczoXG"
      },
      "source": [
        "print('MSE with different regularization factors')\n",
        "fig = plt.figure(figsize = (12, 7))\n",
        "g = sn.lineplot(x=alphas, y=mean_squared_errors, color = 'r').grid()\n",
        "fig.suptitle('MSE with different regularization factors', fontsize = 20)\n",
        "plt.xlabel('Regularization factor from {:e} to {:e}'.format(min(alphas), max(alphas)), fontsize = 14)\n",
        "plt.ylabel('MSE from {:e} to {:e}'.format(min(mean_squared_errors), max(mean_squared_errors)), fontsize = 14)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9iuu2vCCBx3"
      },
      "source": [
        "# Training and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oveBRH_2nzs"
      },
      "source": [
        "%%time\n",
        "print('Training with {} as learning rate and {} as regularization factor'.format(0.00001, alpha))\n",
        "spark_rr = SparkRidgeRegression(n_iterations=n_iterations, learning_rate=0.00001, reg_factor=alpha)\n",
        "now = datetime.now()\n",
        "spark_rr.fit(labeled_train_df)\n",
        "print('==> Done in {}\\n'.format(datetime.now()-now))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koNqmnzQSNgW"
      },
      "source": [
        "%%time\n",
        "print('Predicting')\n",
        "predictions = labeled_test_df.map(lambda prediction: spark_rr.predict(prediction))\n",
        "float_predictions = predictions.map(lambda xs: [float(x) for x in xs])\n",
        "predictions_df = float_predictions.toDF(['label', 'predictions'])\n",
        "print('==> Done\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFqhWTUh2n0B"
      },
      "source": [
        "%%time\n",
        "root_mean_squared_error = spark_rr.root_mean_squared_error(predictions=predictions)\n",
        "mean_squared_error = spark_rr.mean_squared_error(predictions=predictions)\n",
        "mean_absolute_error = spark_rr.mean_absolute_error(predictions=predictions)\n",
        "r2_score = spark_rr.r2(predictions_df)\n",
        "print('From scratch test MSE: {}'.format(mean_squared_error))\n",
        "print('From scratch test RMSE: {}'.format(root_mean_squared_error))\n",
        "print('From scratch test MAE: {}'.format(mean_absolute_error))\n",
        "print('From scratch test R2: {}'.format(r2_score))\n",
        "print('==> Done\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seu2MrQK2n0L"
      },
      "source": [
        "fig = plt.figure(figsize = (12, 7))\n",
        "g = sn.lineplot(x = np.arange(spark_rr.n_iterations), y = spark_rr.training_errors, color = 'crimson').grid()\n",
        "fig.suptitle('Plotting training error during GD iterations', fontsize = 20)\n",
        "plt.xlabel('Iteration', fontsize = 14)\n",
        "plt.ylabel('Training error', fontsize = 14)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDi22jpf_tVr"
      },
      "source": [
        "x = np.array(predictions_df.select('label').collect()).flatten()\n",
        "y = np.array(predictions_df.select('predictions').collect()).flatten()\n",
        "e = [abs(x[i] - y[i]) for i in range(len(x))]\n",
        "df = pd.DataFrame(list(zip(x, y, e)), columns = ['label', 'prediction', 'error'])\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxNAK5w9AT10"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "m, b = np.polyfit(x, y, 1)\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "sns.scatterplot(data=df, x=\"label\", y=\"prediction\", hue='error', palette='coolwarm_r')\n",
        "\n",
        "plt.plot(x, m*x + b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5FQMMtHKz29"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "sns.lineplot(data=df, x=\"label\", y=\"prediction\", legend='full')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}